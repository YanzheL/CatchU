# CNTK 1.7.2 Configuration File

command = Train : Dumpnode

makeMode = false ; traceLevel = 0 ; deviceId = "auto"

rootDir = "." ; dataDir  = "$rootDir$" ; modelDir = "$rootDir$/Models"

precision = "float"

modelPath = "$modelDir$/cnn4face1.cmf"
train_data = "$dataDir$/train_data.txt"
test_data = "$dataDir$/test_data.txt"

# Training action for a convolutional network
Train = {
    action = "train"

    BrainScriptNetworkBuilder = {
        imageShape = 23:27:3
        labelDim = 3

        model (features) = {
	    featNorm = Scale(features - Constant(128.), Constant(1./128.))
	    
	    TanhApprox(x) = x .* Reciprocal( Abs(x) ) .* Minus( Constant(1.), Reciprocal( Constant(1.) + Abs(x) + x .* x + Constant(1.41645) .* x .* x .* x .* x ) )
            ScaleTanhApprox(x) = Constant(0.5) .* TanhApprox( ParameterTensor{1} .* x ) + Constant(0.5)
	    LeakyReLU (x) = ParameterTensor{1} .* x + ParameterTensor{1} .* ReLU (x)

            c11 = ConvolutionalLayer {1, (4:4), pad=false, activation=LeakyReLU, init="gaussian", initValueScale=0.043} (featNorm)
 	    c12 = ConvolutionalLayer {1, (4:4), pad=false, activation=LeakyReLU, init="gaussian", initValueScale=0.043} (featNorm)
            c13 = ConvolutionalLayer {1, (4:4), pad=false, activation=LeakyReLU, init="gaussian", initValueScale=0.043} (featNorm) 
            c14 = ConvolutionalLayer {1, (4:4), pad=false, activation=LeakyReLU, init="gaussian", initValueScale=0.043} (featNorm)
	    
	    bn11 = BatchNormalizationLayer {spatialRank=2, normalizationTimeConstant=5000, epsilon=0.00001, useCntkEngine=false} (c11)
	    bn12 = BatchNormalizationLayer {spatialRank=2, normalizationTimeConstant=5000, epsilon=0.00001, useCntkEngine=false} (c12)
	    bn13 = BatchNormalizationLayer {spatialRank=2, normalizationTimeConstant=5000, epsilon=0.00001, useCntkEngine=false} (c13)
	    bn14 = BatchNormalizationLayer {spatialRank=2, normalizationTimeConstant=5000, epsilon=0.00001, useCntkEngine=false} (c14)

	    p11 = MaxPoolingLayer {(2:2), stride=(2:2)} (bn11)
	    p12 = MaxPoolingLayer {(2:2), stride=(2:2)} (bn12)
	    p13 = MaxPoolingLayer {(2:2), stride=(2:2)} (bn13)
	    p14 = MaxPoolingLayer {(2:2), stride=(2:2)} (bn14)

	    s11 = p11 + p12
	    s12 = p11 + p12 + p13
	    s13 = p12 + p13 + p14
	    s14 = p13 + p14

            c21 = ConvolutionalLayer {1, (3:3), pad=false, activation=LeakyReLU, init="gaussian", initValueScale=0.043} (s11)
 	    c22 = ConvolutionalLayer {1, (3:3), pad=false, activation=LeakyReLU, init="gaussian", initValueScale=0.043} (s11)
            c23 = ConvolutionalLayer {1, (3:3), pad=false, activation=LeakyReLU, init="gaussian", initValueScale=0.043} (s12) 
            c24 = ConvolutionalLayer {1, (3:3), pad=false, activation=LeakyReLU, init="gaussian", initValueScale=0.043} (s12)
            c25 = ConvolutionalLayer {1, (3:3), pad=false, activation=LeakyReLU, init="gaussian", initValueScale=0.043} (s13)
 	    c26 = ConvolutionalLayer {1, (3:3), pad=false, activation=LeakyReLU, init="gaussian", initValueScale=0.043} (s13)
            c27 = ConvolutionalLayer {1, (3:3), pad=false, activation=LeakyReLU, init="gaussian", initValueScale=0.043} (s14) 
            c28 = ConvolutionalLayer {1, (3:3), pad=false, activation=LeakyReLU, init="gaussian", initValueScale=0.043} (s14)

	    bn21 = BatchNormalizationLayer {spatialRank=2, normalizationTimeConstant=5000, epsilon=0.00001, useCntkEngine=false} (c21)
	    bn22 = BatchNormalizationLayer {spatialRank=2, normalizationTimeConstant=5000, epsilon=0.00001, useCntkEngine=false} (c22)
	    bn23 = BatchNormalizationLayer {spatialRank=2, normalizationTimeConstant=5000, epsilon=0.00001, useCntkEngine=false} (c23)
	    bn24 = BatchNormalizationLayer {spatialRank=2, normalizationTimeConstant=5000, epsilon=0.00001, useCntkEngine=false} (c24)
	    bn25 = BatchNormalizationLayer {spatialRank=2, normalizationTimeConstant=5000, epsilon=0.00001, useCntkEngine=false} (c25)
	    bn26 = BatchNormalizationLayer {spatialRank=2, normalizationTimeConstant=5000, epsilon=0.00001, useCntkEngine=false} (c26)
	    bn27 = BatchNormalizationLayer {spatialRank=2, normalizationTimeConstant=5000, epsilon=0.00001, useCntkEngine=false} (c27)
	    bn28 = BatchNormalizationLayer {spatialRank=2, normalizationTimeConstant=5000, epsilon=0.00001, useCntkEngine=false} (c28)

	    p21 = MaxPoolingLayer {(2:2), stride=(2:2)} (bn21)
	    p22 = MaxPoolingLayer {(2:2), stride=(2:2)} (bn22)
	    p23 = MaxPoolingLayer {(2:2), stride=(2:2)} (bn23)
	    p24 = MaxPoolingLayer {(2:2), stride=(2:2)} (bn24)
	    p25 = MaxPoolingLayer {(2:2), stride=(2:2)} (bn25)
	    p26 = MaxPoolingLayer {(2:2), stride=(2:2)} (bn26)
	    p27 = MaxPoolingLayer {(2:2), stride=(2:2)} (bn27)
	    p28 = MaxPoolingLayer {(2:2), stride=(2:2)} (bn28)
	   
	    s21 = p21 + p22
	    s22 = p21 + p22 + p23
	    s23 = p22 + p23 + p24
	    s24 = p23 + p24 + p25
	    s25 = p24 + p25 + p26
	    s26 = p25 + p26 + p27
	    s27 = p26 + p27 + p28
	    s28 = p27 + p28

            c31 = ConvolutionalLayer {1, (4:5), pad=false, activation=LeakyReLU, init="gaussian", initValueScale=0.0414} (s21)
            c32 = ConvolutionalLayer {1, (4:5), pad=false, activation=LeakyReLU, init="gaussian", initValueScale=0.0414} (s21)
            c33 = ConvolutionalLayer {1, (4:5), pad=false, activation=LeakyReLU, init="gaussian", initValueScale=0.0414} (s22)
            c34 = ConvolutionalLayer {1, (4:5), pad=false, activation=LeakyReLU, init="gaussian", initValueScale=0.0414} (s22)
            c35 = ConvolutionalLayer {1, (4:5), pad=false, activation=LeakyReLU, init="gaussian", initValueScale=0.0414} (s23)
            c36 = ConvolutionalLayer {1, (4:5), pad=false, activation=LeakyReLU, init="gaussian", initValueScale=0.0414} (s23)
            c37 = ConvolutionalLayer {1, (4:5), pad=false, activation=LeakyReLU, init="gaussian", initValueScale=0.0414} (s24)
            c38 = ConvolutionalLayer {1, (4:5), pad=false, activation=LeakyReLU, init="gaussian", initValueScale=0.0414} (s24)
            c39 = ConvolutionalLayer {1, (4:5), pad=false, activation=LeakyReLU, init="gaussian", initValueScale=0.0414} (s25)
            c310 = ConvolutionalLayer {1, (4:5), pad=false, activation=LeakyReLU, init="gaussian", initValueScale=0.0414} (s25)
            c311 = ConvolutionalLayer {1, (4:5), pad=false, activation=LeakyReLU, init="gaussian", initValueScale=0.0414} (s26)
            c312 = ConvolutionalLayer {1, (4:5), pad=false, activation=LeakyReLU, init="gaussian", initValueScale=0.0414} (s26)
            c313 = ConvolutionalLayer {1, (4:5), pad=false, activation=LeakyReLU, init="gaussian", initValueScale=0.0414} (s27)
            c314 = ConvolutionalLayer {1, (4:5), pad=false, activation=LeakyReLU, init="gaussian", initValueScale=0.0414} (s27)
            c315 = ConvolutionalLayer {1, (4:5), pad=false, activation=LeakyReLU, init="gaussian", initValueScale=0.0414} (s28)
            c316 = ConvolutionalLayer {1, (4:5), pad=false, activation=LeakyReLU, init="gaussian", initValueScale=0.0414} (s28)

	    bn31 = BatchNormalizationLayer {spatialRank=2, normalizationTimeConstant=5000, epsilon=0.00001, useCntkEngine=false} (c31)
	    bn32 = BatchNormalizationLayer {spatialRank=2, normalizationTimeConstant=5000, epsilon=0.00001, useCntkEngine=false} (c32)
	    bn33 = BatchNormalizationLayer {spatialRank=2, normalizationTimeConstant=5000, epsilon=0.00001, useCntkEngine=false} (c33)
	    bn34 = BatchNormalizationLayer {spatialRank=2, normalizationTimeConstant=5000, epsilon=0.00001, useCntkEngine=false} (c34)
	    bn35 = BatchNormalizationLayer {spatialRank=2, normalizationTimeConstant=5000, epsilon=0.00001, useCntkEngine=false} (c35)
	    bn36 = BatchNormalizationLayer {spatialRank=2, normalizationTimeConstant=5000, epsilon=0.00001, useCntkEngine=false} (c36)
	    bn37 = BatchNormalizationLayer {spatialRank=2, normalizationTimeConstant=5000, epsilon=0.00001, useCntkEngine=false} (c37)
	    bn38 = BatchNormalizationLayer {spatialRank=2, normalizationTimeConstant=5000, epsilon=0.00001, useCntkEngine=false} (c38)
	    bn39 = BatchNormalizationLayer {spatialRank=2, normalizationTimeConstant=5000, epsilon=0.00001, useCntkEngine=false} (c39)
	    bn310 = BatchNormalizationLayer {spatialRank=2, normalizationTimeConstant=5000, epsilon=0.00001, useCntkEngine=false} (c310)
	    bn311 = BatchNormalizationLayer {spatialRank=2, normalizationTimeConstant=5000, epsilon=0.00001, useCntkEngine=false} (c311)
	    bn312 = BatchNormalizationLayer {spatialRank=2, normalizationTimeConstant=5000, epsilon=0.00001, useCntkEngine=false} (c312)
	    bn313 = BatchNormalizationLayer {spatialRank=2, normalizationTimeConstant=5000, epsilon=0.00001, useCntkEngine=false} (c313)
	    bn314 = BatchNormalizationLayer {spatialRank=2, normalizationTimeConstant=5000, epsilon=0.00001, useCntkEngine=false} (c314)
	    bn315 = BatchNormalizationLayer {spatialRank=2, normalizationTimeConstant=5000, epsilon=0.00001, useCntkEngine=false} (c315)
	    bn316 = BatchNormalizationLayer {spatialRank=2, normalizationTimeConstant=5000, epsilon=0.00001, useCntkEngine=false} (c316)

	    concat_1 = RowStack(bn31:bn32:bn33:bn34)
	    h1 = ConvolutionalLayer {4, (4:1), pad=false, activation=ScaleTanhApprox, init="gaussian", initValueScale=0.55} (concat_1)
	    d1 = Dropout (h1)

	    concat_2 = RowStack(bn32:bn33:bn34:bn35)
	    h2 = ConvolutionalLayer {4, (4:1), pad=false, activation=ScaleTanhApprox, init="gaussian", initValueScale=0.55} (concat_2)
	    d2 = Dropout (h2)

	    concat_3 = RowStack(bn33:bn34:bn35:bn36)
	    h3 = ConvolutionalLayer {4, (4:1), pad=false, activation=ScaleTanhApprox, init="gaussian", initValueScale=0.55} (concat_3)
	    d3 = Dropout (h3)

	    concat_4 = RowStack(bn34:bn35:bn36:bn37)
	    h4 = ConvolutionalLayer {4, (4:1), pad=false, activation=ScaleTanhApprox, init="gaussian", initValueScale=0.55} (concat_4)
	    d4 = Dropout (h4)

	    concat_5 = RowStack(bn35:bn36:bn37:bn38)
	    h5 = ConvolutionalLayer {4, (4:1), pad=false, activation=ScaleTanhApprox, init="gaussian", initValueScale=0.55} (concat_5)
	    d5 = Dropout (h5)

	    concat_6 = RowStack(bn36:bn37:bn38:bn39)
	    h6 = ConvolutionalLayer {4, (4:1), pad=false, activation=ScaleTanhApprox, init="gaussian", initValueScale=0.55} (concat_6)
	    d6 = Dropout (h6)

	    concat_7 = RowStack(bn37:bn38:bn39:bn310)
	    h7 = ConvolutionalLayer {4, (4:1), pad=false, activation=ScaleTanhApprox, init="gaussian", initValueScale=0.55} (concat_7)
	    d7 = Dropout (h7)

	    concat_8 = RowStack(bn38:bn39:bn310:bn311)
	    h8 = ConvolutionalLayer {4, (4:1), pad=false, activation=ScaleTanhApprox, init="gaussian", initValueScale=0.55} (concat_8)
	    d8 = Dropout (h8)

	    concat_9 = RowStack(bn39:bn310:bn311:bn312)
	    h9 = ConvolutionalLayer {4, (4:1), pad=false, activation=ScaleTanhApprox, init="gaussian", initValueScale=0.55} (concat_9)
	    d9 = Dropout (h9)

	    concat_10 = RowStack(bn310:bn311:bn312:bn313)
	    h10 = ConvolutionalLayer {4, (4:1), pad=false, activation=ScaleTanhApprox, init="gaussian", initValueScale=0.55} (concat_10)
	    d10 = Dropout (h10)

	    concat_11 = RowStack(bn311:bn312:bn313:bn314)
	    h11 = ConvolutionalLayer {4, (4:1), pad=false, activation=ScaleTanhApprox, init="gaussian", initValueScale=0.55} (concat_11)
	    d11 = Dropout (h11)

	    concat_12 = RowStack(bn312:bn313:bn314:bn315)
	    h12 = ConvolutionalLayer {4, (4:1), pad=false, activation=ScaleTanhApprox, init="gaussian", initValueScale=0.55} (concat_12)
	    d12 = Dropout (h12)

	    concat_13 = RowStack(bn313:bn314:bn315:bn316)
	    h13 = ConvolutionalLayer {4, (4:1), pad=false, activation=ScaleTanhApprox, init="gaussian", initValueScale=0.55} (concat_13)
	    d13 = Dropout (h13)

	    concat_h = RowStack(d1:d2:d3:d4:d5:d6:d7:d8:d9:d10:d11:d12:d13)    

	    bn_h = BatchNormalizationLayer {spatialRank=2, normalizationTimeConstant=15000, epsilon=0.00001, useCntkEngine=false} (concat_h)

	    z = DenseLayer {labelDim, bias=true, activation=ScaleTanhApprox, init="gaussian", initValueScale=1.05} (bn_h)
	}.z

        # inputs
        features = Input {imageShape}
        labels   = Input {labelDim}

        # apply model to features
        z = model (features)

        # connect to system
	sq   = SquareError (labels, z)
        ce   = CrossEntropyWithSoftmax (labels, z)
	le   = Logistic (labels, z)
        errs = ErrorPrediction (labels, z)

        featureNodes    = (features)
        labelNodes      = (labels)
        criterionNodes  = (sq)
        evaluationNodes = (errs)
        outputNodes     = (z)
    }

    SGD = {
        epochSize = 150

        maxEpochs = 100 ; minibatchSize = 128 #128*15:256*20:512:30:1024
        learningRatesPerSample = 0.00095625*1:0.00085625*2:0.00065625*2:0.00045625*2:0.00025625*2:0.00015625*2:0.000095625*2:0.000075625*2:0.000055625*2:0.000025625*2:0.000015625*2:0.0000095625*3:0.0000075625*3:0.0000055625*3:0.0000035625*3:0.0000015625*3:0.00000095625*4:0.00000055625
        momentumAsTimeConstant = 600*10:1200*10:2400*10:6000
        L1RegWeight = 0.0000
	L2RegWeight = 0.0000
	dropoutRate = 0*200000:0.02
	
	# Gradient control
    	#gradientClippingWithTruncation = true
 	#clippingThresholdPerSample = 15.
 	#gaussianNoiseInjectStd = 0
    	gradUpdateType = "fsAdaGrad"
 	#normWithAveMultiplier = true

        firstMBsToShowResult = 10 ; numMBsToShowResult = 100

        autoAdjust = {
#	    autoAdjustLR = "adjustAfterEpoch"
#           learnRateAdjustInterval = 1
#	    useEvalCriterionControlLR = false
#	    reduceLearnRateIfImproveLessThan = 0.001
#           continueReduce = true
#	    loadBestModel = true
#           increaseLearnRateIfImproveMoreThan = 1000000000
#           learnRateDecreaseFactor = 0.7
#           learnRateIncreaseFactor = 1.382


            autoAdjustMinibatch = true       # enable automatic growing of minibatch size
            minibatchSizeTuningFrequency = 20 # try to enlarge after this many epochs
            numMiniBatch4LRSearch = 128
            minibatchSizeTuningMax = 3072    # out of memory above this
        }
    }

    reader = {
        verbosity = 0 ; randomize = true
        deserializers = ({
            type = "ImageDeserializer" ; module = "ImageReader"
            file = "$train_data$"
            input = {
                features = { transforms = (
                    #{ type = "Crop" ; cropType = "Center" ; cropRatio = 0.95 ; jitterType = "uniRatio" ; hflip = true } :
		    { type = "Scale" ; width = 23 ; height = 27 ; channels = 3 ; interpolations = "linear" } :
		    { type = "Transpose" }
                )}
                labels = { labelDim = 3 }
	    }
        })
    }
}

# Eval action
Eval = {
    action = "eval"
    minibatchSize = 256
    evalNodeNames = sqerr
    reader = {
        verbosity = 0 ; randomize = true
        deserializers = ({
            type = "ImageDeserializer" ; module = "ImageReader"
            file = "$test_data$"
            input = {
                features = { transforms = (
                   #{ type = "Crop" ; cropType = "Center" ; cropRatio = 0.8 ; jitterType = "uniRatio" } :
                   { type = "Scale" ; width = 23 ; height = 27 ; channels = 3 ; interpolations = "linear" } :
                   { type = "Transpose" }
                )}
                labels = { labelDim = 3 }
	    }
        })
    }
}


# Output the results
Output = {
    action = "write"
    minibatchSize = 256
    reader = {
        verbosity = 0 ; randomize = true
        deserializers = ({
            type = "ImageDeserializer" ; module = "ImageReader"
            file = "$test_data$"
            input = {
                features = { transforms = (
                   #{ type = "Crop" ; cropType = "Center" ; cropRatio = 0.8 ; jitterType = "uniRatio" } :
                   { type = "Scale" ; width = 23 ; height = 27 ; channels = 3 ; interpolations = "linear" } :
                   { type = "Transpose" }
                )}
                labels = { labelDim = 2 }
	    }	
        })
    }
    outputPath = "OutputPrediction.txt"  # dump the output to this text file
}

# Dumpnode action
Dumpnode = [
    action = "dumpnode"
    #printValues = true
    outputFile = "$rootDir$/cnn4face1_dump.txt"
]